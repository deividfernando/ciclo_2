import streamlit as st
import pandas as pd
from datetime import datetime
from src.components.metrics import *
from src.components.charts import *
from src.utils.plotting import *
from src.config.constants import *

def show_dashboard(df: pd.DataFrame, results: pd.DataFrame):
    """
    Renderiza a p√°gina do dashboard.
    
    Args:
        df (pd.DataFrame): DataFrame com os dados
        results (pd.DataFrame): DataFrame com resultados dos modelos
    """
    # Cabe√ßalho
    st.title("üéØ Dashboard ML Ensemble Analysis")
    
    # Sidebar com filtros
    with st.sidebar:
        st.subheader("Filtros")
        
        # Sele√ß√£o de modelos
        selected_models = st.multiselect(
            "Selecione os modelos",
            options=results['modelo'].unique(),
            default=results['modelo'].unique()
        )
        
        # Sele√ß√£o de m√©tricas
        selected_metrics = st.multiselect(
            "Selecione as m√©tricas",
            options=['Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score', 'AUC-ROC'],
            default=['Acur√°cia', 'F1-Score']
        )
        
        # Atualizar resultados com base nos filtros
        filtered_results = results[
            results['modelo'].isin(selected_models)
        ]

    # Layout principal
    # KPIs principais
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        MetricCard(
            title="Melhor Acur√°cia",
            value=filtered_results['Acur√°cia'].max(),
            delta=f"+{(filtered_results['Acur√°cia'].max() - filtered_results['Acur√°cia'].mean()):.2%}",
            suffix="%",
            description=f"Modelo: {filtered_results.loc[filtered_results['Acur√°cia'].idxmax(), 'modelo']}"
        ).render()
    
    with col2:
        MetricCard(
            title="F1-Score M√©dio",
            value=filtered_results['F1-Score'].mean(),
            suffix="",
            description="M√©dia entre modelos"
        ).render()
    
    with col3:
        MetricCard(
            title="Tempo M√©dio",
            value=filtered_results['tempo_treinamento'].mean(),
            suffix="s",
            description="Tempo de treinamento"
        ).render()
    
    with col4:
        MetricCard(
            title="ROC AUC",
            value=filtered_results['AUC-ROC'].mean(),
            description="M√©dia entre modelos"
        ).render()

    # Gr√°ficos principais
    st.markdown("### üìä An√°lise de Performance")
    
    col1, col2 = st.columns(2)
    
    with col1:
        model_charts = ModelPerformanceCharts(filtered_results)
        metrics_fig = model_charts.metrics_comparison()
        st.plotly_chart(metrics_fig, use_container_width=True)
    
    with col2:
        times_fig = model_charts.training_times()
        st.plotly_chart(times_fig, use_container_width=True)

    # An√°lise de dados
    st.markdown("### üìà An√°lise dos Dados")
    
    col1, col2 = st.columns(2)
    
    with col1:
        data_charts = DataAnalysisCharts(df)
        dist_fig = data_charts.class_distribution()
        st.plotly_chart(dist_fig, use_container_width=True)
    
    with col2:
        missing_fig = data_charts.missing_values()
        st.plotly_chart(missing_fig, use_container_width=True)

    # Compara√ß√£o detalhada de modelos
    st.markdown("### üîç Compara√ß√£o Detalhada de Modelos")
    
    # Tabela de compara√ß√£o
    comparison_df = filtered_results[
        ['modelo', 'Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score', 'AUC-ROC', 'tempo_treinamento']
    ].sort_values('F1-Score', ascending=False)
    
    st.dataframe(
        comparison_df.style.format({
            'Acur√°cia': '{:.2%}',
            'Precis√£o': '{:.2%}',
            'Recall': '{:.2%}',
            'F1-Score': '{:.2%}',
            'AUC-ROC': '{:.2%}',
            'tempo_treinamento': '{:.2f}s'
        }),
        use_container_width=True
    )

    # Gr√°fico radar
    st.markdown("### üìä An√°lise Radar")
    radar_fig = model_charts.model_comparison_radar()
    st.plotly_chart(radar_fig, use_container_width=True)

    # Se√ß√£o de insights
    st.markdown("### üí° Principais Insights")
    
    with st.expander("Ver detalhes"):
        # Melhor modelo
        best_model = filtered_results.loc[filtered_results['F1-Score'].idxmax(), 'modelo']
        best_score = filtered_results['F1-Score'].max()
        
        st.markdown(f"""
        **Melhor Modelo**: {best_model}
        - F1-Score: {best_score:.2%}
        - Caracter√≠sticas do modelo: {MODELS_INFO[best_model]['desc']}
        """)
        
        # Tend√™ncias observadas
        st.markdown("""
        **Tend√™ncias Observadas**:
        - Rela√ß√£o entre tempo de treinamento e performance
        - Balanceamento entre precis√£o e recall
        - Impacto da estrat√©gia de pr√©-processamento
        """)
        
        # Recomenda√ß√µes
        st.markdown("""
        **Recomenda√ß√µes**:
        1. Otimiza√ß√£o de hiperpar√¢metros para modelos espec√≠ficos
        2. Investiga√ß√£o de features importantes
        3. An√°lise de casos de erro comum
        """)

    # Download de relat√≥rio
    st.markdown("### üì• Download do Relat√≥rio")
    
    if st.button("Gerar Relat√≥rio PDF"):
        # TODO: Implementar gera√ß√£o de PDF
        st.info("Funcionalidade em desenvolvimento")

    # Timestamp
    create_timestamp_info()

    # Footer com informa√ß√µes adicionais
    st.markdown("""
    <div style='text-align: center; color: #666; padding: 20px;'>
        <small>
            Dashboard atualizado em tempo real. Dados processados usando Python e Streamlit.<br>
            Desenvolvido pela equipe AlphaEdTech
        </small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    # Para teste local
    import pandas as pd
    
    try:
        df = pd.read_parquet('../data/train.parquet')
        results = pd.read_parquet('../resultados_modelos.parquet')
        show_dashboard(df, results)
    except Exception as e:
        st.error(f"Erro ao carregar dados: {str(e)}")