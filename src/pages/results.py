import streamlit as st
import pandas as pd
from datetime import datetime
from src.components.metrics import *
from src.components.charts import *
from src.utils.plotting import *

def show_results(results: pd.DataFrame):
    """
    Renderiza a p√°gina de resultados e compara√ß√µes.
    
    Args:
        results (pd.DataFrame): DataFrame com os resultados dos modelos
    """
    # Cabe√ßalho
    st.title("üìà Resultados e Compara√ß√µes")
    
    # Sidebar com filtros
    with st.sidebar:
        st.subheader("Filtros")
        
        # Sele√ß√£o de modelos para compara√ß√£o
        selected_models = st.multiselect(
            "Selecione os modelos para comparar",
            options=results['modelo'].unique(),
            default=results['modelo'].unique()
        )
        
        # Sele√ß√£o de m√©tricas
        selected_metrics = st.multiselect(
            "M√©tricas para visualiza√ß√£o",
            options=['Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score', 'AUC-ROC'],
            default=['Acur√°cia', 'F1-Score', 'AUC-ROC']
        )
        
        # Op√ß√µes de visualiza√ß√£o
        show_details = st.checkbox("Mostrar Detalhes", value=True)
        show_statistics = st.checkbox("Mostrar Estat√≠sticas", value=True)
        
        # Filtrar resultados
        filtered_results = results[results['modelo'].isin(selected_models)]

    # Resumo das m√©tricas
    st.markdown("### üìä Resumo das M√©tricas")
    metrics_grid = create_model_metrics_summary(filtered_results)
    metrics_grid.render()

    # An√°lise Comparativa
    st.markdown("### üîÑ An√°lise Comparativa")
    
    tabs = st.tabs(["M√©tricas", "Performance", "An√°lise Detalhada"])
    
    # Tab de M√©tricas
    with tabs[0]:
        model_charts = ModelPerformanceCharts(filtered_results)
        
        # Gr√°fico de m√©tricas
        st.plotly_chart(model_charts.metrics_comparison(), use_container_width=True)
        
        if show_statistics:
            # Tabela detalhada
            st.markdown("#### üìã M√©tricas Detalhadas")
            detailed_metrics = filtered_results[
                ['modelo', 'Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score', 'AUC-ROC']
            ].sort_values('F1-Score', ascending=False)
            
            st.dataframe(
                detailed_metrics.style.format({
                    col: '{:.4f}' for col in detailed_metrics.columns if col != 'modelo'
                }),
                use_container_width=True
            )
            
            # An√°lise estat√≠stica
            st.markdown("#### üìä An√°lise Estat√≠stica")
            stats_df = detailed_metrics.describe()
            st.dataframe(stats_df.style.format('{:.4f}'), use_container_width=True)
    
    # Tab de Performance
    with tabs[1]:
        col1, col2 = st.columns(2)
        
        with col1:
            # Tempo de treinamento
            st.markdown("#### ‚è±Ô∏è Tempo de Treinamento")
            st.plotly_chart(model_charts.training_times(), use_container_width=True)
        
        with col2:
            # Gr√°fico radar
            st.markdown("#### üéØ Compara√ß√£o Radar")
            st.plotly_chart(model_charts.model_comparison_radar(), use_container_width=True)
        
        if show_details:
            st.markdown("#### üí° Insights de Performance")
            
            # Melhor modelo em cada m√©trica
            best_models = pd.DataFrame({
                'M√©trica': selected_metrics,
                'Melhor Modelo': [
                    filtered_results.loc[filtered_results[metric].idxmax(), 'modelo']
                    for metric in selected_metrics
                ],
                'Valor': [
                    filtered_results[metric].max()
                    for metric in selected_metrics
                ]
            })
            
            st.dataframe(
                best_models.style.format({
                    'Valor': '{:.4f}'
                }),
                use_container_width=True
            )
    
    # Tab de An√°lise Detalhada
    with tabs[2]:
        # Sele√ß√£o de modelo espec√≠fico
        selected_model = st.selectbox(
            "Selecione um modelo para an√°lise detalhada",
            options=selected_models
        )
        
        if selected_model:
            model_data = filtered_results[filtered_results['modelo'] == selected_model].iloc[0]
            
            # M√©tricas espec√≠ficas do modelo
            st.markdown("#### üìä M√©tricas Detalhadas")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                MetricCard(
                    title="Acur√°cia",
                    value=model_data['Acur√°cia'],
                    color="#1f77b4"
                ).render()
            
            with col2:
                MetricCard(
                    title="F1-Score",
                    value=model_data['F1-Score'],
                    color="#2ca02c"
                ).render()
            
            with col3:
                MetricCard(
                    title="AUC-ROC",
                    value=model_data['AUC-ROC'],
                    color="#ff7f0e"
                ).render()
            
            # An√°lise por classe
            st.markdown("#### üìà An√°lise por Classe")
            
            class_metrics = pd.DataFrame({
                'Classe': ['0', '1'],
                'Precis√£o': [
                    model_data['Precis√£o_Classe_0'],
                    model_data['Precis√£o_Classe_1']
                ],
                'Recall': [
                    model_data['Recall_Classe_0'],
                    model_data['Recall_Classe_1']
                ],
                'F1-Score': [
                    model_data['F1-Score_Classe_0'],
                    model_data['F1-Score_Classe_1']
                ]
            })
            
            st.dataframe(
                class_metrics.style.format({
                    col: '{:.4f}' for col in class_metrics.columns if col != 'Classe'
                }),
                use_container_width=True
            )

    # Se√ß√£o de Download
    st.markdown("### üì• Download dos Resultados")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Download CSV
        if st.button("Download CSV"):
            csv = filtered_results.to_csv(index=False)
            st.download_button(
                label="Confirmar Download CSV",
                data=csv,
                file_name=f"resultados_modelos_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
    
    with col2:
        # Download relat√≥rio
        if st.button("Gerar Relat√≥rio"):
            report = f"""
            # Relat√≥rio de Resultados - {datetime.now().strftime('%Y-%m-%d')}
            
            ## Resumo dos Modelos Analisados
            
            {filtered_results[['modelo', 'Acur√°cia', 'F1-Score', 'AUC-ROC']].to_markdown()}
            
            ## M√©tricas por Classe
            
            ### Classe 0
            {filtered_results[['modelo', 'Precis√£o_Classe_0', 'Recall_Classe_0', 'F1-Score_Classe_0']].to_markdown()}
            
            ### Classe 1
            {filtered_results[['modelo', 'Precis√£o_Classe_1', 'Recall_Classe_1', 'F1-Score_Classe_1']].to_markdown()}
            
            ## Performance
            
            Tempos de treinamento:
            {filtered_results[['modelo', 'tempo_treinamento']].to_markdown()}
            
            ## Conclus√µes
            
            - Melhor modelo em Acur√°cia: {filtered_results.loc[filtered_results['Acur√°cia'].idxmax(), 'modelo']}
            - Melhor modelo em F1-Score: {filtered_results.loc[filtered_results['F1-Score'].idxmax(), 'modelo']}
            - Modelo mais r√°pido: {filtered_results.loc[filtered_results['tempo_treinamento'].idxmin(), 'modelo']}
            """
            
            st.download_button(
                label="Baixar Relat√≥rio",
                data=report,
                file_name=f"relatorio_resultados_{datetime.now().strftime('%Y%m%d')}.md",
                mime="text/markdown"
            )

    # Conclus√µes
    st.markdown("### üí° Conclus√µes")
    
    with st.expander("Ver an√°lise completa"):
        # Melhor modelo geral
        best_model = filtered_results.loc[filtered_results['F1-Score'].idxmax(), 'modelo']
        best_score = filtered_results['F1-Score'].max()
        
        st.markdown(f"""
        #### üèÜ Melhor Modelo: {best_model}
        
        - F1-Score: {best_score:.4f}
        - Tempo de treinamento: {filtered_results.loc[filtered_results['F1-Score'].idxmax(), 'tempo_treinamento']:.2f}s
        
        #### üìà An√°lise Geral
        
        - Distribui√ß√£o das m√©tricas entre os modelos
        - Trade-off entre performance e tempo de treinamento
        - Comportamento por classe
        
        """)

    # Timestamp
    create_timestamp_info()

if __name__ == "__main__":
    # Para teste local
    try:
        results = pd.read_parquet('../resultados_modelos.parquet')
        show_results(results)
    except Exception as e:
        st.error(f"Erro ao carregar resultados: {str(e)}")