import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from utils import *
import plotly.express as px
import plotly.graph_objects as go
from streamlit_option_menu import option_menu

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="ML Ensemble Analysis Dashboard",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Estilo CSS personalizado
st.markdown(
    """
    <style>
        .main {
            padding: 0rem 1rem;
        }
        .stAlert {
            padding: 1rem;
            border-radius: 0.5rem;
        }
        h1 {
            color: #1E88E5;
        }
        h2 {
            color: #424242;
        }
        .stProgress .st-bo {
            background-color: #1E88E5;
        }
    </style>
""",
    unsafe_allow_html=True,
)


# Fun√ß√£o para carregar dados
@st.cache_data
def load_data():
    # Substitua isso pelo seu pr√≥prio carregamento de dados
    return pd.read_csv("predicoes_finais.csv")


# Sidebar com navega√ß√£o
with st.sidebar:
    selected = option_menu(
        menu_title="Navigation",
        options=[
            "Home",
            "ML Theory",
            "Data Analysis",
            "Model Training",
            "Results",
            "About",
        ],
        icons=["house", "book", "bar-chart", "gear", "graph-up", "info-circle"],
        menu_icon="cast",
        default_index=0,
    )

# P√°gina inicial
if selected == "Home":
    st.title("ü§ñ Machine Learning Ensemble Analysis")

    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown(
            """
        ## Sobre o Projeto
        Este dashboard apresenta uma an√°lise completa do desafio de Machine Learning utilizando
        modelos ensemble. Aqui voc√™ encontrar√°:
        
        - üìä An√°lise explorat√≥ria dos dados
        - üîç Compara√ß√£o entre diferentes modelos
        - üìà M√©tricas de performance
        - üéØ Resultados e insights
        """
        )

    with col2:
        st.info(
            "üëà Use o menu lateral para navegar entre as diferentes se√ß√µes do dashboard"
        )

# Teoria do ML
elif selected == "ML Theory":
    st.title("üìö Fundamentos Te√≥ricos dos Modelos Ensemble")

    st.markdown(
        """
    ## üîÑ M√©todos Ensemble
    Os m√©todos ensemble s√£o t√©cnicas avan√ßadas de machine learning que combinam m√∫ltiplos modelos base 
    para produzir um modelo preditivo aprimorado. A principal vantagem dessa abordagem √© a redu√ß√£o da 
    vari√¢ncia e do vi√©s, resultando em previs√µes mais robustas e confi√°veis.

    ### üå≥ Random Forest
    O Random Forest √© um algoritmo de ensemble learning baseado em √°rvores de decis√£o que opera atrav√©s 
    do princ√≠pio de bagging (Bootstrap Aggregating). Caracter√≠sticas principais:
    """
    )

    col1, col2 = st.columns(2)

    with col1:
        st.info(
            "**Funcionamento do Random Forest**\n\n"
            "- Cria√ß√£o de m√∫ltiplas √°rvores de decis√£o\n"
            "- Amostragem aleat√≥ria com reposi√ß√£o\n"
            "- Sele√ß√£o aleat√≥ria de features\n"
            "- Vota√ß√£o majorit√°ria para classifica√ß√£o"
        )

    with col2:
        st.info(
            "**Vantagens**\n\n"
            "- Redu√ß√£o do overfitting\n"
            "- Robusto a outliers\n"
            "- Paraleliz√°vel\n"
            "- Import√¢ncia das features"
        )

    st.markdown(
        """
    ### üìà Gradient Boosting
    O Gradient Boosting √© uma t√©cnica de ensemble que constr√≥i modelos de forma sequencial, 
    onde cada novo modelo tenta corrigir os erros dos modelos anteriores. As implementa√ß√µes 
    modernas incluem:
    """
    )

    col3, col4 = st.columns(2)

    with col3:
        st.warning(
            "**XGBoost**\n\n"
            "- Implementa√ß√£o otimizada\n"
            "- Regulariza√ß√£o integrada\n"
            "- Tratamento eficiente de dados esparsos\n"
            "- Alta performance"
        )

    with col4:
        st.warning(
            "**LightGBM**\n\n"
            "- Crescimento de √°rvore baseado em folhas\n"
            "- Menor uso de mem√≥ria\n"
            "- Treinamento mais r√°pido\n"
            "- Suporte a dados categ√≥ricos"
        )

    # Adicionar compara√ß√£o t√©cnica
    st.subheader("üîç Compara√ß√£o T√©cnica dos Modelos")

    comparison_df = pd.DataFrame(
        {
            "Caracter√≠stica": [
                "M√©todo Base",
                "Constru√ß√£o",
                "Complexidade",
                "Paraleliza√ß√£o",
                "Uso de Mem√≥ria",
            ],
            "Random Forest": [
                "Bagging",
                "Paralela",
                "O(n_trees * n_samples * log(n_samples))",
                "Alta",
                "Moderado",
            ],
            "Gradient Boosting": [
                "Boosting",
                "Sequencial",
                "O(n_trees * n_samples * log(n_samples))",
                "Limitada",
                "Baixo",
            ],
        }
    )

    st.table(comparison_df)

    # Nota t√©cnica final
    st.info(
        "üìù **Observa√ß√£o T√©cnica**\n\n"
        "A escolha entre Random Forest e Gradient Boosting frequentemente envolve um "
        "trade-off entre velocidade de treinamento, capacidade de paraleliza√ß√£o e "
        "performance do modelo. Random Forest tende a ser mais robusto e f√°cil de "
        "ajustar, enquanto Gradient Boosting geralmente oferece melhor performance "
        "com ajuste adequado dos hiperpar√¢metros."
    )

# P√°gina de an√°lise de dados
elif selected == "Data Analysis":
    st.title("üìä An√°lise Explorat√≥ria dos Dados")

    tab1, tab2, tab3 = st.tabs(["Distribui√ß√£o", "Correla√ß√µes", "Missing Values"])

    with tab1:
        st.header("Distribui√ß√£o das Features")
        # Adicione seus gr√°ficos de distribui√ß√£o aqui

    with tab2:
        st.header("Matriz de Correla√ß√£o")
        # Adicione seu heatmap de correla√ß√£o aqui

    with tab3:
        st.header("An√°lise de Dados Faltantes")
        # Adicione sua an√°lise de dados faltantes aqui

# P√°gina de treinamento
elif selected == "Model Training":
    st.title("‚öôÔ∏è Treinamento dos Modelos")

    st.header("Configura√ß√£o dos Modelos")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Random Forest")
        rf_estimators = st.slider("N√∫mero de Estimadores (RF)", 100, 500, 200)
        rf_depth = st.slider("Profundidade M√°xima (RF)", 10, 100, 30)

    with col2:
        st.subheader("Gradient Boosting")
        gb_estimators = st.slider("N√∫mero de Estimadores (GB)", 100, 500, 200)
        gb_depth = st.slider("Profundidade M√°xima (GB)", 3, 10, 5)

    if st.button("Iniciar Treinamento"):
        with st.spinner("Treinando modelos..."):
            # Adicione seu c√≥digo de treinamento aqui
            st.success("Treinamento conclu√≠do!")

# P√°gina de resultados
elif selected == "Results":
    st.title("üìà Resultados e Compara√ß√µes")

    tab1, tab2 = st.tabs(["M√©tricas", "Import√¢ncia das Features"])

    with tab1:
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("Acur√°cia RF", "0.85", "+0.03")
        with col2:
            st.metric("Acur√°cia XGBoost", "0.87", "+0.05")
        with col3:
            st.metric("Acur√°cia LightGBM", "0.86", "+0.04")

        # Adicione mais visualiza√ß√µes de m√©tricas aqui

    with tab2:
        st.header("Import√¢ncia das Features")
        # Adicione seu gr√°fico de import√¢ncia das features aqui

# P√°gina sobre
else:
    st.title("‚ÑπÔ∏è Sobre")

    st.markdown(
        """
    ## Desafio de Fim de Ciclo 2 - AlphaEdtech
    
    Este projeto faz parte do desafio final do ciclo 2 do curso de Python na AlphaEdtech, 
    onde o objetivo √© realizar an√°lises de Machine Learning utilizando modelos baseados em ensembles.
    
    ### üéØ Objetivos
    1. Avaliar o impacto do n√∫mero de √°rvores e profundidade no desempenho dos modelos
    2. Comparar o tempo de treinamento entre Random Forest e Gradient Boosting
    3. Analisar as vari√°veis mais importantes para o Random Forest
    4. Otimizar hiperpar√¢metros dos modelos
    
    ### üõ†Ô∏è Ferramentas Utilizadas
    - Python
    - Scikit-learn
    - XGBoost
    - LightGBM
    - Streamlit
    - Plotly
    """
    )

    st.balloons()


def main():
    # Seu c√≥digo principal aqui
    pass


if __name__ == "__main__":
    main()
