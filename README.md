# Desafio de Fim de Ciclo 2 - AlphaEdtech

## ğŸ“‹ DescriÃ§Ã£o do Projeto
Este projeto faz parte do desafio final do ciclo 2 do curso de Python na AlphaEdtech. O objetivo Ã© realizar anÃ¡lises de Machine Learning (ML) utilizando modelos baseados em ensembles. O dataset fornecido Ã© anÃ´nimo, e a missÃ£o Ã© aplicar tÃ©cnicas avanÃ§adas de treinamento e otimizaÃ§Ã£o de modelos para avaliar o desempenho de algoritmos de aprendizado supervisionado.

## ğŸ¯ Objetivos Principais
1. Avaliar o impacto do nÃºmero de Ã¡rvores e profundidade no desempenho dos modelos
2. Comparar o tempo de treinamento entre **Random Forest** e **Gradient Boosting**
3. Analisar as variÃ¡veis mais importantes para o **Random Forest** e sua interpretaÃ§Ã£o
4. Otimizar hiperparÃ¢metros dos modelos usando tÃ©cnicas como **Grid Search** ou **Random Search**
5. Desenvolver modelos de classificaÃ§Ã£o robustos usando tÃ©cnicas de ensemble learning
6. Comparar diferentes estratÃ©gias de tratamento de dados nulos
7. Avaliar o impacto da reduÃ§Ã£o de dimensionalidade (PCA) no desempenho dos modelos

## ğŸ” Modelos e AnÃ¡lises
### Modelos Implementados
- Random Forest
- XGBoost
- LightGBM

### EstratÃ©gias de PrÃ©-processamento
- MÃ©dia
- Mediana
- Moda
- Constante
- AnÃ¡lise personalizada por coluna

### MÃ©tricas de Desempenho
- AcurÃ¡cia
- PrecisÃ£o, Recall e F1-Score
- Matriz de ConfusÃ£o
- Curva ROC e AUC

### TÃ©cnicas de OtimizaÃ§Ã£o
- ReduÃ§Ã£o de dimensionalidade via PCA
- Balanceamento de classes com SMOTE
- RandomizedSearchCV para otimizaÃ§Ã£o de hiperparÃ¢metros

## ğŸ’¡ Justificativa de Escolha dos Modelos
Cada modelo foi escolhido com base nas caracterÃ­sticas especÃ­ficas do problema:
- **Random Forest**: Escolhido por sua robustez contra overfitting e boa performance em dados de alta dimensionalidade
- **Gradient Boosting (XGBoost/LightGBM)**: Selecionado por sua alta performance em competiÃ§Ãµes de ML e capacidade de lidar com dados complexos

## ğŸ“Š Resultados Principais
- **Melhor Modelo**: LightGBM com estratÃ©gia de anÃ¡lise de colunas
  - AcurÃ¡cia: 86.51%
  - PrecisÃ£o Classe 0: 57.47%
  - PrecisÃ£o Classe 1: 88.28%
  - PontuaÃ§Ã£o mÃ©dia: 77.42%

- **Desempenho no Conjunto de Teste Final**:
  - AcurÃ¡cia: 80.23%
  - PrecisÃ£o: 81.21%
  - Recall: 97.02%
  - F1-Score: 88.42%

## ğŸ”§ PrÃ©-processamento de Dados
A qualidade do prÃ©-processamento foi essencial para o sucesso do projeto:
- Correta divisÃ£o dos dados
- Tratamento de outliers
- ImputaÃ§Ã£o de dados faltantes
- AnÃ¡lise do impacto da normalizaÃ§Ã£o no desempenho
- TÃ©cnicas de reduÃ§Ã£o de dimensionalidade

## ğŸ› ï¸ Ambiente de Desenvolvimento
- **Linguagem:** Python 3.x
- **Principais Bibliotecas:** 
  - scikit-learn
  - xgboost
  - lightgbm
  - pandas
  - numpy
  - matplotlib
  - seaborn
  - imblearn
- **IDEs e Ferramentas:**
  - Visual Studio Code
  - GitHub
  - Google Colab (experimentaÃ§Ã£o e treinamento em nuvem)

## ğŸ“¦ Estrutura do Projeto
```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.parquet
â”‚   â””â”€â”€ test.parquet
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ functions.py
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ treinamento.ipynb
â”‚   â”œâ”€â”€ analise_modelos.ipynb
â”‚   â””â”€â”€ analise_resultados.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸš€ InstruÃ§Ãµes de InstalaÃ§Ã£o e ExecuÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/deividfernando/ciclo_2.git
cd ciclo_2
```

2. Configure o ambiente virtual:
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Execute os notebooks na ordem:
   - `treinamento.ipynb`
   - `analise_modelos.ipynb`
   - `analise_resultados.ipynb`

5. Visualize os resultados no dashboard interativo:
```bash
streamlit run app.py
```
O dashboard serÃ¡ aberto automaticamente no seu navegador padrÃ£o (geralmente em http://localhost:8501) e oferece:
   - ğŸ  VisÃ£o geral do projeto e navegaÃ§Ã£o intuitiva
   - ğŸ“Š AnÃ¡lise exploratÃ³ria dos dados (distribuiÃ§Ãµes, correlaÃ§Ãµes e dados faltantes)
   - âš™ï¸ Interface para configuraÃ§Ã£o e treinamento dos modelos
   - ğŸ“ˆ VisualizaÃ§Ã£o das mÃ©tricas de performance e resultados
   - â„¹ï¸ InformaÃ§Ãµes sobre objetivos e ferramentas utilizadas

**Nota**: Certifique-se de que todos os notebooks foram executados antes de iniciar o dashboard, pois ele depende dos arquivos de resultados gerados durante o treinamento e anÃ¡lise dos modelos.

## ğŸ“ˆ Features e AnÃ¡lises AvanÃ§adas
- AnÃ¡lise estatÃ­stica completa de distribuiÃ§Ãµes
- MÃºltiplas estratÃ©gias de tratamento de dados nulos
- OtimizaÃ§Ã£o avanÃ§ada de hiperparÃ¢metros
- AnÃ¡lise de importÃ¢ncia de features
- VisualizaÃ§Ãµes detalhadas de performance

## ğŸ¤ ContribuiÃ§Ãµes
ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:
1. FaÃ§a um Fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/NovaFuncionalidade`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/NovaFuncionalidade`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a
Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.
