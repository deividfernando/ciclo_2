# Desafio de Fim de Ciclo 2 - AlphaEdtech

Este projeto faz parte do desafio final do ciclo 2 do curso de Python na AlphaEdtech, onde o objetivo √© realizar an√°lises de Machine Learning (ML) utilizando modelos baseados em ensembles. O dataset fornecido √© an√¥nimo, e a miss√£o √© aplicar t√©cnicas avan√ßadas de treinamento e otimiza√ß√£o de modelos para avaliar o desempenho de algoritmos de aprendizado supervisionado.

## üìö Sobre o Projeto

O desafio consiste em treinar e comparar dois modelos de ML baseados em √°rvores de decis√£o: **Random Forest** e **Gradient Boosting** (utilizando XGBoost ou LightGBM). O foco √© entender como a combina√ß√£o de v√°rias √°rvores de decis√£o (ensembles) pode melhorar a performance dos modelos e reduzir o overfitting.

## üéØ Objetivos

1. Avaliar o impacto do n√∫mero de √°rvores e profundidade no desempenho dos modelos.
2. Comparar o tempo de treinamento entre **Random Forest** e **Gradient Boosting**.
3. Analisar as vari√°veis mais importantes para o **Random Forest** e sua interpreta√ß√£o.
4. Otimizar hiperpar√¢metros dos modelos usando t√©cnicas como **Grid Search** ou **Random Search**.

## üîç An√°lises e M√©tricas

Durante o treinamento e avalia√ß√£o dos modelos, monitoramos as seguintes m√©tricas de desempenho:

- **Acur√°cia**
- **Precis√£o**, **Recall** e **F1-Score**
- **Matriz de Confus√£o**
- **Curva ROC e AUC**

### Interpreta√ß√£o dos Modelos

Analisamos as vari√°veis mais importantes que impactam cada modelo, verificamos o overfitting atrav√©s de **cross-validation** e discutimos como as escolhas influenciam o problema abordado.

### Ajuste de Hiperpar√¢metros

Para otimizar o desempenho, aplicamos t√©cnicas de ajuste de hiperpar√¢metros, como:

- **Grid Search**
- **Random Search**

## üîß Pr√©-processamento de Dados

A qualidade do pr√©-processamento foi essencial para o sucesso do projeto. A etapa incluiu:

- Correta **divis√£o dos dados**
- **Tratamento de outliers**
- **Imputa√ß√£o** de dados faltantes
- An√°lise de como a **normaliza√ß√£o** afeta o desempenho dos modelos

## üí° Justificativa de Escolha dos Modelos

Cada modelo foi escolhido com base nas caracter√≠sticas do problema abordado e sua capacidade de lidar com dados complexos, como o **Random Forest**, que √© robusto contra overfitting, e o **Gradient Boosting**, conhecido por sua alta performance em competi√ß√µes de ML.

## üìä Resultados

Os resultados dos modelos foram avaliados utilizando m√©tricas como **AUC-ROC**, **F1-Score**, entre outras, e as vari√°veis mais importantes foram identificadas e interpretadas para justificar as decis√µes tomadas durante o processo.

## üõ† Ferramentas Utilizadas

- **Linguagem:** Python
- **Bibliotecas:** Scikit-learn, XGBoost, LightGBM, Matplotlib, Seaborn
- **Ambiente de Desenvolvimento:** Visual Studio Code, GitHub
- **Outras Ferramentas:** Google Colab para experimenta√ß√£o e treinamento em nuvem

## üöÄ Instru√ß√µes de Instala√ß√£o e Execu√ß√£o

Siga os passos abaixo para configurar e executar o projeto localmente:


**1. Clone o reposit√≥rio:**
```bash
  git clone https://github.com/deividfernando/ciclo_2.git

```

**2. Navegue at√© o diret√≥rio do projeto:**
```bash
   cd ciclo_2
```

**3. Crie um ambiente virtual (opcional, mas recomendado):**
```bash
   - No Windows:
     python -m venv venv
     venv\Scripts\activate
   - No macOS/Linux:
     python3 -m venv venv
     source venv/bin/activate
```
**4. Instale as depend√™ncias:**
```bash
   pip install -r requirements.txt
```

